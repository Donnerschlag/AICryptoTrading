{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'columns': ['Close', 'Volume', 'Low', 'High'],\n",
       " 'csv_src_file': 'BTC_ETH',\n",
       " 'filename': 'BTC_ETH_lstm_i288_o144_Close_Volume_Low_High',\n",
       " 'folder': {'data': 'data/', 'weights': 'weights/'},\n",
       " 'input_size': 288,\n",
       " 'lstm_hidden_size': 200,\n",
       " 'name': 'lstm',\n",
       " 'output_size': 144,\n",
       " 'pair': 'BTC_ETH',\n",
       " 'period': 30}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from config import CONFIG\n",
    "from utils import series_to_supervised\n",
    "\n",
    "CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>269507</th>\n",
       "      <td>0.082828</td>\n",
       "      <td>1519862700</td>\n",
       "      <td>0.082856</td>\n",
       "      <td>0.082729</td>\n",
       "      <td>0.082729</td>\n",
       "      <td>4.151247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269508</th>\n",
       "      <td>0.082609</td>\n",
       "      <td>1519863000</td>\n",
       "      <td>0.082828</td>\n",
       "      <td>0.082606</td>\n",
       "      <td>0.082828</td>\n",
       "      <td>5.551513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269509</th>\n",
       "      <td>0.082552</td>\n",
       "      <td>1519863300</td>\n",
       "      <td>0.082673</td>\n",
       "      <td>0.082547</td>\n",
       "      <td>0.082609</td>\n",
       "      <td>2.327443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269510</th>\n",
       "      <td>0.082460</td>\n",
       "      <td>1519863600</td>\n",
       "      <td>0.082625</td>\n",
       "      <td>0.082419</td>\n",
       "      <td>0.082552</td>\n",
       "      <td>1.519736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269511</th>\n",
       "      <td>0.082455</td>\n",
       "      <td>1519863900</td>\n",
       "      <td>0.082460</td>\n",
       "      <td>0.082418</td>\n",
       "      <td>0.082455</td>\n",
       "      <td>0.552411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Close   Timestamp      High       Low      Open    Volume\n",
       "269507  0.082828  1519862700  0.082856  0.082729  0.082729  4.151247\n",
       "269508  0.082609  1519863000  0.082828  0.082606  0.082828  5.551513\n",
       "269509  0.082552  1519863300  0.082673  0.082547  0.082609  2.327443\n",
       "269510  0.082460  1519863600  0.082625  0.082419  0.082552  1.519736\n",
       "269511  0.082455  1519863900  0.082460  0.082418  0.082455  0.552411"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from matplotlib import pyplot\n",
    " \n",
    "#data file path\n",
    "dfp = ''.join([CONFIG['folder']['data'], CONFIG['csv_src_file'], '.csv'])\n",
    "\n",
    "#Columns of price data to use\n",
    "columns = CONFIG['columns']\n",
    "# df = pd.read_csv(dfp).dropna().tail(1000000)\n",
    "dataset = pd.read_csv(dfp)\n",
    "\n",
    "# to drop values before 2018 1514764800, March 2018 1519862400, July 2017 1498867200\n",
    "dataset = dataset[dataset.Timestamp > 1519862400]\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = dataset.loc[:,columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 4, 144)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters to prepare the dataset for learning \n",
    "n_lag = CONFIG['input_size']\n",
    "n_out = CONFIG['output_size']\n",
    "n_features = len(columns)\n",
    "n_lag,n_features,n_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-288)</th>\n",
       "      <th>var2(t-288)</th>\n",
       "      <th>var3(t-288)</th>\n",
       "      <th>var4(t-288)</th>\n",
       "      <th>var1(t-287)</th>\n",
       "      <th>var2(t-287)</th>\n",
       "      <th>var3(t-287)</th>\n",
       "      <th>var4(t-287)</th>\n",
       "      <th>var1(t-286)</th>\n",
       "      <th>var2(t-286)</th>\n",
       "      <th>...</th>\n",
       "      <th>var3(t+141)</th>\n",
       "      <th>var4(t+141)</th>\n",
       "      <th>var1(t+142)</th>\n",
       "      <th>var2(t+142)</th>\n",
       "      <th>var3(t+142)</th>\n",
       "      <th>var4(t+142)</th>\n",
       "      <th>var1(t+143)</th>\n",
       "      <th>var2(t+143)</th>\n",
       "      <th>var3(t+143)</th>\n",
       "      <th>var4(t+143)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>0.911499</td>\n",
       "      <td>0.005383</td>\n",
       "      <td>0.909966</td>\n",
       "      <td>0.888220</td>\n",
       "      <td>0.904896</td>\n",
       "      <td>0.007199</td>\n",
       "      <td>0.906295</td>\n",
       "      <td>0.887362</td>\n",
       "      <td>0.903185</td>\n",
       "      <td>0.003018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.782275</td>\n",
       "      <td>0.765320</td>\n",
       "      <td>0.795766</td>\n",
       "      <td>0.003916</td>\n",
       "      <td>0.787687</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.781310</td>\n",
       "      <td>0.008893</td>\n",
       "      <td>0.783815</td>\n",
       "      <td>0.765188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>0.904896</td>\n",
       "      <td>0.007199</td>\n",
       "      <td>0.906295</td>\n",
       "      <td>0.887362</td>\n",
       "      <td>0.903185</td>\n",
       "      <td>0.003018</td>\n",
       "      <td>0.904533</td>\n",
       "      <td>0.882607</td>\n",
       "      <td>0.900404</td>\n",
       "      <td>0.001971</td>\n",
       "      <td>...</td>\n",
       "      <td>0.787687</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.781310</td>\n",
       "      <td>0.008893</td>\n",
       "      <td>0.783815</td>\n",
       "      <td>0.765188</td>\n",
       "      <td>0.785669</td>\n",
       "      <td>0.005755</td>\n",
       "      <td>0.783381</td>\n",
       "      <td>0.759371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>0.903185</td>\n",
       "      <td>0.003018</td>\n",
       "      <td>0.904533</td>\n",
       "      <td>0.882607</td>\n",
       "      <td>0.900404</td>\n",
       "      <td>0.001971</td>\n",
       "      <td>0.900683</td>\n",
       "      <td>0.881134</td>\n",
       "      <td>0.900251</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.783815</td>\n",
       "      <td>0.765188</td>\n",
       "      <td>0.785669</td>\n",
       "      <td>0.005755</td>\n",
       "      <td>0.783381</td>\n",
       "      <td>0.759371</td>\n",
       "      <td>0.783557</td>\n",
       "      <td>0.005765</td>\n",
       "      <td>0.783872</td>\n",
       "      <td>0.759353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>0.900404</td>\n",
       "      <td>0.001971</td>\n",
       "      <td>0.900683</td>\n",
       "      <td>0.881134</td>\n",
       "      <td>0.900251</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>0.900682</td>\n",
       "      <td>0.876073</td>\n",
       "      <td>0.899950</td>\n",
       "      <td>0.001567</td>\n",
       "      <td>...</td>\n",
       "      <td>0.783381</td>\n",
       "      <td>0.759371</td>\n",
       "      <td>0.783557</td>\n",
       "      <td>0.005765</td>\n",
       "      <td>0.783872</td>\n",
       "      <td>0.759353</td>\n",
       "      <td>0.785995</td>\n",
       "      <td>0.007049</td>\n",
       "      <td>0.785897</td>\n",
       "      <td>0.759686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>0.900251</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>0.900682</td>\n",
       "      <td>0.876073</td>\n",
       "      <td>0.899950</td>\n",
       "      <td>0.001567</td>\n",
       "      <td>0.899785</td>\n",
       "      <td>0.879122</td>\n",
       "      <td>0.900536</td>\n",
       "      <td>0.001585</td>\n",
       "      <td>...</td>\n",
       "      <td>0.783872</td>\n",
       "      <td>0.759353</td>\n",
       "      <td>0.785995</td>\n",
       "      <td>0.007049</td>\n",
       "      <td>0.785897</td>\n",
       "      <td>0.759686</td>\n",
       "      <td>0.792811</td>\n",
       "      <td>0.006897</td>\n",
       "      <td>0.788341</td>\n",
       "      <td>0.766715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>0.899950</td>\n",
       "      <td>0.001567</td>\n",
       "      <td>0.899785</td>\n",
       "      <td>0.879122</td>\n",
       "      <td>0.900536</td>\n",
       "      <td>0.001585</td>\n",
       "      <td>0.899590</td>\n",
       "      <td>0.876207</td>\n",
       "      <td>0.898062</td>\n",
       "      <td>0.002247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785897</td>\n",
       "      <td>0.759686</td>\n",
       "      <td>0.792811</td>\n",
       "      <td>0.006897</td>\n",
       "      <td>0.788341</td>\n",
       "      <td>0.766715</td>\n",
       "      <td>0.786108</td>\n",
       "      <td>0.005211</td>\n",
       "      <td>0.786491</td>\n",
       "      <td>0.766776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>0.900536</td>\n",
       "      <td>0.001585</td>\n",
       "      <td>0.899590</td>\n",
       "      <td>0.876207</td>\n",
       "      <td>0.898062</td>\n",
       "      <td>0.002247</td>\n",
       "      <td>0.899590</td>\n",
       "      <td>0.877975</td>\n",
       "      <td>0.900530</td>\n",
       "      <td>0.001073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.788341</td>\n",
       "      <td>0.766715</td>\n",
       "      <td>0.786108</td>\n",
       "      <td>0.005211</td>\n",
       "      <td>0.786491</td>\n",
       "      <td>0.766776</td>\n",
       "      <td>0.780843</td>\n",
       "      <td>0.008527</td>\n",
       "      <td>0.781111</td>\n",
       "      <td>0.759659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0.898062</td>\n",
       "      <td>0.002247</td>\n",
       "      <td>0.899590</td>\n",
       "      <td>0.877975</td>\n",
       "      <td>0.900530</td>\n",
       "      <td>0.001073</td>\n",
       "      <td>0.899590</td>\n",
       "      <td>0.876218</td>\n",
       "      <td>0.898052</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.786491</td>\n",
       "      <td>0.766776</td>\n",
       "      <td>0.780843</td>\n",
       "      <td>0.008527</td>\n",
       "      <td>0.781111</td>\n",
       "      <td>0.759659</td>\n",
       "      <td>0.780722</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>0.781258</td>\n",
       "      <td>0.754445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0.900530</td>\n",
       "      <td>0.001073</td>\n",
       "      <td>0.899590</td>\n",
       "      <td>0.876218</td>\n",
       "      <td>0.898052</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>0.899590</td>\n",
       "      <td>0.877294</td>\n",
       "      <td>0.900246</td>\n",
       "      <td>0.001661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.781111</td>\n",
       "      <td>0.759659</td>\n",
       "      <td>0.780722</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>0.781258</td>\n",
       "      <td>0.754445</td>\n",
       "      <td>0.778586</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>0.781111</td>\n",
       "      <td>0.754322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0.898052</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>0.899590</td>\n",
       "      <td>0.877294</td>\n",
       "      <td>0.900246</td>\n",
       "      <td>0.001661</td>\n",
       "      <td>0.899590</td>\n",
       "      <td>0.876158</td>\n",
       "      <td>0.900536</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.781258</td>\n",
       "      <td>0.754445</td>\n",
       "      <td>0.778586</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>0.781111</td>\n",
       "      <td>0.754322</td>\n",
       "      <td>0.780722</td>\n",
       "      <td>0.001369</td>\n",
       "      <td>0.781113</td>\n",
       "      <td>0.754322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 1728 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     var1(t-288)  var2(t-288)  var3(t-288)  var4(t-288)  var1(t-287)  \\\n",
       "288     0.911499     0.005383     0.909966     0.888220     0.904896   \n",
       "289     0.904896     0.007199     0.906295     0.887362     0.903185   \n",
       "290     0.903185     0.003018     0.904533     0.882607     0.900404   \n",
       "291     0.900404     0.001971     0.900683     0.881134     0.900251   \n",
       "292     0.900251     0.000716     0.900682     0.876073     0.899950   \n",
       "293     0.899950     0.001567     0.899785     0.879122     0.900536   \n",
       "294     0.900536     0.001585     0.899590     0.876207     0.898062   \n",
       "295     0.898062     0.002247     0.899590     0.877975     0.900530   \n",
       "296     0.900530     0.001073     0.899590     0.876218     0.898052   \n",
       "297     0.898052     0.000990     0.899590     0.877294     0.900246   \n",
       "\n",
       "     var2(t-287)  var3(t-287)  var4(t-287)  var1(t-286)  var2(t-286)  \\\n",
       "288     0.007199     0.906295     0.887362     0.903185     0.003018   \n",
       "289     0.003018     0.904533     0.882607     0.900404     0.001971   \n",
       "290     0.001971     0.900683     0.881134     0.900251     0.000716   \n",
       "291     0.000716     0.900682     0.876073     0.899950     0.001567   \n",
       "292     0.001567     0.899785     0.879122     0.900536     0.001585   \n",
       "293     0.001585     0.899590     0.876207     0.898062     0.002247   \n",
       "294     0.002247     0.899590     0.877975     0.900530     0.001073   \n",
       "295     0.001073     0.899590     0.876218     0.898052     0.000990   \n",
       "296     0.000990     0.899590     0.877294     0.900246     0.001661   \n",
       "297     0.001661     0.899590     0.876158     0.900536     0.000313   \n",
       "\n",
       "        ...       var3(t+141)  var4(t+141)  var1(t+142)  var2(t+142)  \\\n",
       "288     ...          0.782275     0.765320     0.795766     0.003916   \n",
       "289     ...          0.787687     0.769936     0.781310     0.008893   \n",
       "290     ...          0.783815     0.765188     0.785669     0.005755   \n",
       "291     ...          0.783381     0.759371     0.783557     0.005765   \n",
       "292     ...          0.783872     0.759353     0.785995     0.007049   \n",
       "293     ...          0.785897     0.759686     0.792811     0.006897   \n",
       "294     ...          0.788341     0.766715     0.786108     0.005211   \n",
       "295     ...          0.786491     0.766776     0.780843     0.008527   \n",
       "296     ...          0.781111     0.759659     0.780722     0.002326   \n",
       "297     ...          0.781258     0.754445     0.778586     0.001087   \n",
       "\n",
       "     var3(t+142)  var4(t+142)  var1(t+143)  var2(t+143)  var3(t+143)  \\\n",
       "288     0.787687     0.769936     0.781310     0.008893     0.783815   \n",
       "289     0.783815     0.765188     0.785669     0.005755     0.783381   \n",
       "290     0.783381     0.759371     0.783557     0.005765     0.783872   \n",
       "291     0.783872     0.759353     0.785995     0.007049     0.785897   \n",
       "292     0.785897     0.759686     0.792811     0.006897     0.788341   \n",
       "293     0.788341     0.766715     0.786108     0.005211     0.786491   \n",
       "294     0.786491     0.766776     0.780843     0.008527     0.781111   \n",
       "295     0.781111     0.759659     0.780722     0.002326     0.781258   \n",
       "296     0.781258     0.754445     0.778586     0.001087     0.781111   \n",
       "297     0.781111     0.754322     0.780722     0.001369     0.781113   \n",
       "\n",
       "     var4(t+143)  \n",
       "288     0.765188  \n",
       "289     0.759371  \n",
       "290     0.759353  \n",
       "291     0.759686  \n",
       "292     0.766715  \n",
       "293     0.766776  \n",
       "294     0.759659  \n",
       "295     0.754445  \n",
       "296     0.754322  \n",
       "297     0.754322  \n",
       "\n",
       "[10 rows x 1728 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, n_lag, n_out)\n",
    "reframed.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-288)</th>\n",
       "      <th>var2(t-288)</th>\n",
       "      <th>var3(t-288)</th>\n",
       "      <th>var4(t-288)</th>\n",
       "      <th>var1(t-287)</th>\n",
       "      <th>var2(t-287)</th>\n",
       "      <th>var3(t-287)</th>\n",
       "      <th>var4(t-287)</th>\n",
       "      <th>var1(t-286)</th>\n",
       "      <th>var2(t-286)</th>\n",
       "      <th>...</th>\n",
       "      <th>var1(t+134)</th>\n",
       "      <th>var1(t+135)</th>\n",
       "      <th>var1(t+136)</th>\n",
       "      <th>var1(t+137)</th>\n",
       "      <th>var1(t+138)</th>\n",
       "      <th>var1(t+139)</th>\n",
       "      <th>var1(t+140)</th>\n",
       "      <th>var1(t+141)</th>\n",
       "      <th>var1(t+142)</th>\n",
       "      <th>var1(t+143)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>0.911499</td>\n",
       "      <td>0.005383</td>\n",
       "      <td>0.909966</td>\n",
       "      <td>0.888220</td>\n",
       "      <td>0.904896</td>\n",
       "      <td>0.007199</td>\n",
       "      <td>0.906295</td>\n",
       "      <td>0.887362</td>\n",
       "      <td>0.903185</td>\n",
       "      <td>0.003018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.798666</td>\n",
       "      <td>0.803870</td>\n",
       "      <td>0.798064</td>\n",
       "      <td>0.798062</td>\n",
       "      <td>0.793931</td>\n",
       "      <td>0.791549</td>\n",
       "      <td>0.784497</td>\n",
       "      <td>0.791533</td>\n",
       "      <td>0.795766</td>\n",
       "      <td>0.781310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>0.904896</td>\n",
       "      <td>0.007199</td>\n",
       "      <td>0.906295</td>\n",
       "      <td>0.887362</td>\n",
       "      <td>0.903185</td>\n",
       "      <td>0.003018</td>\n",
       "      <td>0.904533</td>\n",
       "      <td>0.882607</td>\n",
       "      <td>0.900404</td>\n",
       "      <td>0.001971</td>\n",
       "      <td>...</td>\n",
       "      <td>0.803870</td>\n",
       "      <td>0.798064</td>\n",
       "      <td>0.798062</td>\n",
       "      <td>0.793931</td>\n",
       "      <td>0.791549</td>\n",
       "      <td>0.784497</td>\n",
       "      <td>0.791533</td>\n",
       "      <td>0.795766</td>\n",
       "      <td>0.781310</td>\n",
       "      <td>0.785669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>0.903185</td>\n",
       "      <td>0.003018</td>\n",
       "      <td>0.904533</td>\n",
       "      <td>0.882607</td>\n",
       "      <td>0.900404</td>\n",
       "      <td>0.001971</td>\n",
       "      <td>0.900683</td>\n",
       "      <td>0.881134</td>\n",
       "      <td>0.900251</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.798064</td>\n",
       "      <td>0.798062</td>\n",
       "      <td>0.793931</td>\n",
       "      <td>0.791549</td>\n",
       "      <td>0.784497</td>\n",
       "      <td>0.791533</td>\n",
       "      <td>0.795766</td>\n",
       "      <td>0.781310</td>\n",
       "      <td>0.785669</td>\n",
       "      <td>0.783557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>0.900404</td>\n",
       "      <td>0.001971</td>\n",
       "      <td>0.900683</td>\n",
       "      <td>0.881134</td>\n",
       "      <td>0.900251</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>0.900682</td>\n",
       "      <td>0.876073</td>\n",
       "      <td>0.899950</td>\n",
       "      <td>0.001567</td>\n",
       "      <td>...</td>\n",
       "      <td>0.798062</td>\n",
       "      <td>0.793931</td>\n",
       "      <td>0.791549</td>\n",
       "      <td>0.784497</td>\n",
       "      <td>0.791533</td>\n",
       "      <td>0.795766</td>\n",
       "      <td>0.781310</td>\n",
       "      <td>0.785669</td>\n",
       "      <td>0.783557</td>\n",
       "      <td>0.785995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>0.900251</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>0.900682</td>\n",
       "      <td>0.876073</td>\n",
       "      <td>0.899950</td>\n",
       "      <td>0.001567</td>\n",
       "      <td>0.899785</td>\n",
       "      <td>0.879122</td>\n",
       "      <td>0.900536</td>\n",
       "      <td>0.001585</td>\n",
       "      <td>...</td>\n",
       "      <td>0.793931</td>\n",
       "      <td>0.791549</td>\n",
       "      <td>0.784497</td>\n",
       "      <td>0.791533</td>\n",
       "      <td>0.795766</td>\n",
       "      <td>0.781310</td>\n",
       "      <td>0.785669</td>\n",
       "      <td>0.783557</td>\n",
       "      <td>0.785995</td>\n",
       "      <td>0.792811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1296 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     var1(t-288)  var2(t-288)  var3(t-288)  var4(t-288)  var1(t-287)  \\\n",
       "288     0.911499     0.005383     0.909966     0.888220     0.904896   \n",
       "289     0.904896     0.007199     0.906295     0.887362     0.903185   \n",
       "290     0.903185     0.003018     0.904533     0.882607     0.900404   \n",
       "291     0.900404     0.001971     0.900683     0.881134     0.900251   \n",
       "292     0.900251     0.000716     0.900682     0.876073     0.899950   \n",
       "\n",
       "     var2(t-287)  var3(t-287)  var4(t-287)  var1(t-286)  var2(t-286)  \\\n",
       "288     0.007199     0.906295     0.887362     0.903185     0.003018   \n",
       "289     0.003018     0.904533     0.882607     0.900404     0.001971   \n",
       "290     0.001971     0.900683     0.881134     0.900251     0.000716   \n",
       "291     0.000716     0.900682     0.876073     0.899950     0.001567   \n",
       "292     0.001567     0.899785     0.879122     0.900536     0.001585   \n",
       "\n",
       "        ...       var1(t+134)  var1(t+135)  var1(t+136)  var1(t+137)  \\\n",
       "288     ...          0.798666     0.803870     0.798064     0.798062   \n",
       "289     ...          0.803870     0.798064     0.798062     0.793931   \n",
       "290     ...          0.798064     0.798062     0.793931     0.791549   \n",
       "291     ...          0.798062     0.793931     0.791549     0.784497   \n",
       "292     ...          0.793931     0.791549     0.784497     0.791533   \n",
       "\n",
       "     var1(t+138)  var1(t+139)  var1(t+140)  var1(t+141)  var1(t+142)  \\\n",
       "288     0.793931     0.791549     0.784497     0.791533     0.795766   \n",
       "289     0.791549     0.784497     0.791533     0.795766     0.781310   \n",
       "290     0.784497     0.791533     0.795766     0.781310     0.785669   \n",
       "291     0.791533     0.795766     0.781310     0.785669     0.783557   \n",
       "292     0.795766     0.781310     0.785669     0.783557     0.785995   \n",
       "\n",
       "     var1(t+143)  \n",
       "288     0.781310  \n",
       "289     0.785669  \n",
       "290     0.783557  \n",
       "291     0.785995  \n",
       "292     0.792811  \n",
       "\n",
       "[5 rows x 1296 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop columns we don't want to predict\n",
    "# We're only concerned with the estimating the close value,\n",
    "# Close should be first in the list of column in the config file\n",
    "\n",
    "cols_to_drop = []\n",
    "\n",
    "for i in range (n_out):\n",
    "    for j in range(1, n_features):\n",
    "        cols_to_drop.append(reframed.shape[1]-(i*n_features+j))\n",
    "\n",
    "reframed.drop(reframed.columns[cols_to_drop], axis=1, inplace=True)\n",
    "\n",
    "reframed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reframed_values = reframed.values\n",
    "# split into train and test sets\n",
    "training_size = int(0.8* reframed_values.shape[0])\n",
    "train = reframed_values[:training_size, :]\n",
    "test = reframed_values[training_size:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((23320, 288, 4), (23320, 144, 1), (5831, 288, 4), (5831, 144, 1))\n"
     ]
    }
   ],
   "source": [
    "# split into input and outputs\n",
    "n_obs = n_lag * n_features\n",
    "\n",
    "# We're only concerned with the estimating the close value,\n",
    "# Close should be first in the list of column in the config file\n",
    "\n",
    "n_outputs = n_out * n_features\n",
    "train_x, train_y = train[:, :n_obs], train[:, -n_out:]\n",
    "test_x, test_y = test[:, :n_obs], test[:, -n_out:]\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_x = train_x.reshape((train_x.shape[0], n_lag, n_features))\n",
    "test_x = test_x.reshape((test_x.shape[0], n_lag, n_features))\n",
    "\n",
    "# reshape output to be 3D [samples, timesteps, features]\n",
    "train_y = train_y.reshape(-1, n_out, 1)\n",
    "test_y = test_y.reshape(-1, n_out, 1)\n",
    "\n",
    "print(train_x.shape, train_y.shape, test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=''.join([CONFIG['folder']['weights'], CONFIG['filename'], '_model', '.json'])\n",
    "model_weights_name=''.join([CONFIG['folder']['weights'], CONFIG['filename'], '_model_weights', '.h5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_1 (Bidirection (None, 400)               328000    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 144, 400)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 144, 100)          200400    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 144, 100)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 144, 1)            101       \n",
      "=================================================================\n",
      "Total params: 528,501\n",
      "Trainable params: 528,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input\n",
    "from keras.layers import LSTM, CuDNNLSTM, GRU,CuDNNGRU\n",
    "from keras.layers import Conv1D, AveragePooling1D, MaxPooling1D\n",
    "from keras.layers import Dropout, Flatten\n",
    "from keras.layers import Activation, BatchNormalization\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import RepeatVector\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "units= CONFIG['lstm_hidden_size']\n",
    "dropout = .1\n",
    "\n",
    "# design network\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(units), input_shape=(train_x.shape[1], train_x.shape[2])))\n",
    "model.add(Dropout(dropout))\n",
    "\n",
    "model.add(RepeatVector(n_out))\n",
    "\n",
    "model.add(LSTM(units/2, return_sequences=True))\n",
    "model.add(Dropout(dropout))\n",
    "\n",
    "# We're only concerned with the estimating the close value,\n",
    "# otherwise use n_outputs instead of 1\n",
    "# Dense(n_outputs, ...\n",
    "model.add(TimeDistributed(Dense(1, activation='relu')))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# store model\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(model_name, \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=100\n",
    "batch_size=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23320 samples, validate on 5831 samples\n",
      "Epoch 1/100\n",
      "23320/23320 [==============================] - 26s 1ms/step - loss: 0.0223 - val_loss: 0.0098\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00979, saving model to weights/BTC_ETH_lstm_i288_o144_Close_Volume_Low_High_model_weights.h5\n",
      "Epoch 2/100\n",
      "23320/23320 [==============================] - 27s 1ms/step - loss: 0.0091 - val_loss: 0.0070\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00979 to 0.00700, saving model to weights/BTC_ETH_lstm_i288_o144_Close_Volume_Low_High_model_weights.h5\n",
      "Epoch 3/100\n",
      "23320/23320 [==============================] - 27s 1ms/step - loss: 0.0095 - val_loss: 0.0034\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00700 to 0.00339, saving model to weights/BTC_ETH_lstm_i288_o144_Close_Volume_Low_High_model_weights.h5\n",
      "Epoch 4/100\n",
      "22528/23320 [===========================>..] - ETA: 0s - loss: 0.0095"
     ]
    }
   ],
   "source": [
    "# fit network\n",
    "history = model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size,\n",
    "                    validation_data=(test_x, test_y), verbose=1, shuffle=False,\n",
    "                    callbacks=[ModelCheckpoint(model_weights_name, monitor='val_loss', verbose=1,save_best_only='true',\n",
    "                                              save_weights_only=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best weights\n",
    "model.load_weights(model_weights_name)\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the prediction of test data\n",
    "y = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = test_y[:,0]\n",
    "b = y[:,0]\n",
    "c = np.append(b, y[-1], axis=0)\n",
    "\n",
    "# Show how the model fits the test data\n",
    "pyplot.plot(a[:100], label='original')\n",
    "pyplot.plot(b[:100], label='model')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    "\n",
    "# Show how the model predicts data\n",
    "pos = int(a.shape[0]-n_out*4)\n",
    "pyplot.plot(a[pos:], label='original')\n",
    "pyplot.plot(c[pos:], label='model')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction on public data!\n",
    "period = CONFIG['period']\n",
    "import time\n",
    "import urllib2\n",
    "import json\n",
    "\n",
    "# Download a live bitcoin price data set\n",
    "def dl_X(now = None, points = n_lag, period = period, pair=CONFIG['pair']):\n",
    "    if now == None:\n",
    "        now = time.time() \n",
    "    end = now - now % period\n",
    "    #print end, time.strftime(\"%a, %d %b %Y %H:%M:%S +0000\", time.gmtime(end))\n",
    "    start = end - points*period\n",
    "    #print start, time.strftime(\"%a, %d %b %Y %H:%M:%S +0000\", time.gmtime(start))\n",
    "    url = \"https://poloniex.com/public?command=returnChartData&currencyPair=%s&start=%d&end=%d&period=%d\" % (pair, start, end, period)\n",
    "    openUrl = urllib2.urlopen(url)\n",
    "    r = openUrl.read()\n",
    "    openUrl.close()\n",
    "    d = json.loads(r.decode())[-n_lag:]\n",
    "    df = pd.DataFrame(d)\n",
    "    original_columns=[u'close', u'date', u'high', u'low', u'open',u'volume']\n",
    "    new_columns = ['Close','Timestamp','High','Low','Open','Volume']\n",
    "    df = df.loc[:,original_columns]\n",
    "    df.columns = new_columns\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(when=None):\n",
    "    rt_df = dl_X(when)\n",
    "    rt_values = rt_df.loc[:,columns].values\n",
    "    rt_scaled = scaler.transform(rt_values)\n",
    "    rt_x = rt_scaled.reshape((1, n_lag, n_features))\n",
    "    print rt_x.shape\n",
    "    return rt_scaled, model.predict(rt_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do some now & past predictions\n",
    "for t in [0, 100, 200, 300, 500, 1000, 2000]:\n",
    "    rt_x, prediction = predict(time.time()-t*period)\n",
    "\n",
    "    current = rt_x[:,0]\n",
    "    prediction = prediction[0]\n",
    "\n",
    "    pyplot.plot(current, label='current')\n",
    "\n",
    "    # shift train predictions for plotting\n",
    "    predictPlot = np.empty_like(current)\n",
    "    predictPlot[:] = np.nan\n",
    "    predictPlot = np.append(predictPlot, prediction)\n",
    "\n",
    "    pyplot.plot(predictPlot, label='prediction')\n",
    "    pyplot.legend()\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction on live data!\n",
    "starttime=time.time()\n",
    "while True:\n",
    "    now = time.time() \n",
    "    end = now - now % period\n",
    "    print time.strftime(\"%a, %d %b %Y %H:%M:%S +0000\", time.gmtime(end))\n",
    "    rt_x, prediction = predict()\n",
    "\n",
    "    current = rt_x[:,0]\n",
    "    prediction = prediction[0]\n",
    "\n",
    "    pyplot.plot(current, label='current')\n",
    "\n",
    "    # shift train predictions for plotting\n",
    "    predictPlot = np.empty_like(current)\n",
    "    predictPlot[:] = np.nan\n",
    "    predictPlot = np.append(predictPlot, prediction)\n",
    "\n",
    "    pyplot.plot(predictPlot, label='prediction')\n",
    "    pyplot.legend()\n",
    "    pyplot.show()\n",
    "\n",
    "    time.sleep(period - ((time.time() - starttime) % period))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
